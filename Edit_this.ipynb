{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtrmcldPhzQbc5OI6oWb7+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d56b9b30d02409aa0c77941abc71152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bf2267d33f84efcb7f4cb360d87c037",
              "IPY_MODEL_6543946fb1984137a022a68ff5aba430",
              "IPY_MODEL_546c3f71ce8a40a396d8b883362bff61"
            ],
            "layout": "IPY_MODEL_6a9a4804e3aa40afb649d0d36cba6be1"
          }
        },
        "2bf2267d33f84efcb7f4cb360d87c037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a726210c9252488db201c0777fcfd553",
            "placeholder": "​",
            "style": "IPY_MODEL_60205bd77f9642088a69ed5b91b864ba",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6543946fb1984137a022a68ff5aba430": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f24639f0715f4694a61499c5abb8dc9d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d9fa25f33984abe93f8c4ecb0457af1",
            "value": 2
          }
        },
        "546c3f71ce8a40a396d8b883362bff61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c1057637daf41b9a45524272d354bf9",
            "placeholder": "​",
            "style": "IPY_MODEL_7594b667d91040ffa0ac21ef1019a78d",
            "value": " 2/2 [00:25&lt;00:00, 10.80s/it]"
          }
        },
        "6a9a4804e3aa40afb649d0d36cba6be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a726210c9252488db201c0777fcfd553": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60205bd77f9642088a69ed5b91b864ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f24639f0715f4694a61499c5abb8dc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9fa25f33984abe93f8c4ecb0457af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c1057637daf41b9a45524272d354bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7594b667d91040ffa0ac21ef1019a78d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malik-Zubair123/Gemma2_Hackathon/blob/main/Edit_this.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uQBt1sT87JSf",
        "outputId": "c6257d97-320b-4487-f323-b00781daa5d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os"
      ],
      "metadata": {
        "id": "vcuamq6Z7Xw4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TranscriptSummarizer:\n",
        "    def __init__(self, model_name=\"google/gemma-2b\"):\n",
        "        \"\"\"\n",
        "        Initialize the summarization model and tokenizer\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Hugging Face model to use for summarization\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load tokenizer and model with specific configurations\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "            # Set pad token if not already set\n",
        "            if self.tokenizer.pad_token is None:\n",
        "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "                self.model.config.pad_token_id = self.model.config.eos_token_id\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Model loading error: {e}\")\n",
        "            raise\n",
        "\n",
        "    def preprocess_text(self, text, max_length=2048):\n",
        "        \"\"\"\n",
        "        Preprocess input text for summarization with improved truncation\n",
        "\n",
        "        Args:\n",
        "            text (str): Input text to preprocess\n",
        "            max_length (int): Maximum token length to allow\n",
        "\n",
        "        Returns:\n",
        "            str: Cleaned and processed text\n",
        "        \"\"\"\n",
        "        # Remove extra whitespaces\n",
        "        cleaned_text = ' '.join(text.split())\n",
        "\n",
        "        # Truncate text to manageable length\n",
        "        tokens = self.tokenizer.encode(\n",
        "            cleaned_text,\n",
        "            truncation=True,\n",
        "            max_length=max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return self.tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "\n",
        "    def generate_summary(self, text, max_new_tokens=150):\n",
        "        \"\"\"\n",
        "        Generate summary using the loaded model with enhanced error handling\n",
        "\n",
        "        Args:\n",
        "            text (str): Text to summarize\n",
        "            max_new_tokens (int): Maximum number of new tokens to generate\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Preprocess the text with length control\n",
        "            processed_text = self.preprocess_text(text)\n",
        "\n",
        "            print(f\"Processed Text Size: {len(processed_text)} characters\")\n",
        "\n",
        "            # Construct a prompt that explicitly requests a summary\n",
        "            summary_prompt = f\"Summarize the following text concisely:\\n{processed_text}\\n\\nSummary:\"\n",
        "\n",
        "            # Prepare inputs with error checking\n",
        "            inputs = self.tokenizer(\n",
        "                summary_prompt,\n",
        "                return_tensors=\"pt\",\n",
        "                truncation=True,\n",
        "                max_length=2048,\n",
        "                padding=True\n",
        "            )\n",
        "\n",
        "            # Generate summary with more robust parameters\n",
        "            summary_ids = self.model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                num_return_sequences=1,\n",
        "                no_repeat_ngram_size=2,\n",
        "                do_sample=True,\n",
        "                top_k=50,\n",
        "                top_p=0.95,\n",
        "                temperature=0.7,\n",
        "                pad_token_id=self.tokenizer.pad_token_id\n",
        "            )\n",
        "\n",
        "            # Decode the summary\n",
        "            summary = self.tokenizer.decode(\n",
        "                summary_ids[0][inputs['input_ids'].shape[1]:],  # Only decode new generated tokens\n",
        "                skip_special_tokens=True\n",
        "            )\n",
        "\n",
        "            return summary.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Detailed Summary Generation Error: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return f\"Could not generate summary. Error: {str(e)}\"\n",
        "\n",
        "# Function to handle different input scenarios\n",
        "def summarize_text(input_text=None, file_path=None, max_new_tokens=150):\n",
        "    \"\"\"\n",
        "    Flexible function to summarize text from different sources\n",
        "\n",
        "    Args:\n",
        "        input_text (str, optional): Direct text input\n",
        "        file_path (str, optional): Path to text file\n",
        "        max_new_tokens (int, optional): Maximum new tokens in summary\n",
        "\n",
        "    Returns:\n",
        "        str: Generated summary\n",
        "    \"\"\"\n",
        "    # Initialize summarizer\n",
        "    summarizer = TranscriptSummarizer()\n",
        "\n",
        "    # Determine text source\n",
        "    if input_text:\n",
        "        text = input_text\n",
        "    elif file_path:\n",
        "        try:\n",
        "            with open(file_path, 'r', encoding='utf-8') as file:\n",
        "                text = file.read()\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading file: {e}\")\n",
        "            return f\"File reading error: {e}\"\n",
        "    else:\n",
        "        return \"No text provided. Please give input text or file path.\"\n",
        "\n",
        "    # Generate and return summary\n",
        "    return summarizer.generate_summary(text, max_new_tokens)\n",
        "\n",
        "# Example Usage\n",
        "def main():\n",
        "    # Option 1: Directly input text\n",
        "    sample_text = \"\"\"\n",
        "    Key Advantages of Plain Text Files:\n",
        "Plain text will never require a subscription, lock away features, or go out of business. It's free and here forever.\n",
        "\n",
        "Flexibility: Open Them Anywhere: Plain text files are the most flexible file format we have. They can be opened by hundreds, if not thousands, of applications. Since they are a basic component of computers, you can even open them on the computer command line.\n",
        "No New Tools: We all get excited by new stuff, and for productivity junkies, we perk up with excitement to try out a new piece of software. Unfortunately tools come and go, and switching system can be wasteful and counterproductive. Switching to plain text means you never need to migrate to a new tool.\n",
        "Portability: By portability I mean that your files can be moved to and from different operating systems, platforms and devices and you can still open them. Whether you are on a Mac, Linux, Windows or some future tool, you'll be able to open and edit your plain text files there.\n",
        "Future-Proof: A while back I discovered several writings I did in high school using Windows 95 and a version of Microsoft Word. While I was able to eventually open the files, the formatting had been lost. This revealed a potential danger in locking your words into a format that may not be around forever. Fortunately, while other file formats may come and go, plain text files will remain.\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate summary from text\n",
        "    summary = summarize_text(input_text=sample_text, max_new_tokens=100)\n",
        "    print(\"Generated Summary:\")\n",
        "    print(summary)"
      ],
      "metadata": {
        "id": "BrOF2iWY-A-f"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "5d56b9b30d02409aa0c77941abc71152",
            "2bf2267d33f84efcb7f4cb360d87c037",
            "6543946fb1984137a022a68ff5aba430",
            "546c3f71ce8a40a396d8b883362bff61",
            "6a9a4804e3aa40afb649d0d36cba6be1",
            "a726210c9252488db201c0777fcfd553",
            "60205bd77f9642088a69ed5b91b864ba",
            "f24639f0715f4694a61499c5abb8dc9d",
            "8d9fa25f33984abe93f8c4ecb0457af1",
            "6c1057637daf41b9a45524272d354bf9",
            "7594b667d91040ffa0ac21ef1019a78d"
          ]
        },
        "id": "REVBwHZG9aDb",
        "outputId": "00533e17-0f21-488a-d7ba-cf3464274e8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d56b9b30d02409aa0c77941abc71152"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed Text Size: 1386 characters\n",
            "Generated Summary:\n",
            "1. Plain-text files have been around since the first computers.\n",
            "2. There are many advantages to using plain-texts. The best one is that they won't disappear. You can open, edit, share, move, print, save, email, open in a browser, etc., plain texts with any program. That means there is no need for proprietary software, no licensing fees, subscription fees or anything else. Plus, there are millions of free, powerful tools that will\n"
          ]
        }
      ]
    }
  ]
}
